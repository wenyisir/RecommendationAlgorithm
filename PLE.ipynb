{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60fba432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from tower_layer.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from tower_layer import tower_layer\n",
    "import os\n",
    "from typing import List, Tuple, Any\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import feature_column as fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49be5b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练参数\n",
    "model_dir = \"model\\\\model_dir\\\\PLE\" #Directory where model parameters, graph, etc are saved\n",
    "output_dir = \"model\\\\output_dir\\\\PLE\" #Directory where pb file are saved\n",
    "\n",
    "train_data = \"E:/Deep Learning/dataset/wechat_bigdata/tfrecord/train.tfrecord\" #Path to the train data\n",
    "eval_data = \"E:/Deep Learning/dataset/wechat_bigdata/tfrecord/test.tfrecord\" #Path to the evaluation data\n",
    "vocabulary_dir = \"E:/Deep Learning/dataset/wechat_bigdata/vocabulary/\" #Folder where the vocabulary file is stored\n",
    "num_epochs = 10 #Epoch of training phase\n",
    "train_steps = 10000 #Number of (global) training steps to perform\n",
    "shuffle_buffer_size = 10000 #Dataset shuffle buffer size\n",
    "num_parallel_readers = -1 #Number of parallel readers for training data\n",
    "save_checkpoints_steps = 1000 #Save checkpoints every this many steps\n",
    "\n",
    "# 模型参数\n",
    "batch_size = 1024 #Training batch size\n",
    "learning_rate = 0.005 #Learning rate\n",
    "hidden_units = [512,256,128] #Comma-separated list of number of units in each hidden layer of the final output part\n",
    "batch_norm = True, #Perform batch normalization (True or False)\n",
    "dropout_rate = 0.1 #Dropout rate\n",
    "\n",
    "expert_hidden_units = 256 #Expert module output dimension\n",
    "num_tasks = 3 #Number of tasks, that's number of gates\n",
    "task_names = [\"read_comment\",\"like\",\"click_avatar\"] #Comma-separated list of task names, each must be in keys of tfrecord file\n",
    "\n",
    "num_extract_network = 1\n",
    "num_experts_per_task = [5,5,5]\n",
    "num_experts_in_shared = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "374a4973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 返回一个 tuple \n",
    "def create_feature_columns() -> Tuple[list, list, list]:\n",
    "    \"\"\"\n",
    "        生成模型输入特征和label\n",
    "    Returns:\n",
    "        dense_feature_columns (list): 连续特征的feature_columns\n",
    "        category_feature_columns (list): 类别特征的feature_columns(包括序列特征)\n",
    "        label_feature_columns (list): 因变量的feature_columns\n",
    "    \"\"\"\n",
    "\n",
    "    dense_feature_columns, category_feature_columns, label_feature_columns = [], [], []\n",
    "\n",
    "    # 连续特征\n",
    "    videoplayseconds = fc.numeric_column('videoplayseconds', default_value=0.0)\n",
    "    u_read_comment_7d_sum = fc.numeric_column('u_read_comment_7d_sum', default_value=0.0)\n",
    "    u_like_7d_sum = fc.numeric_column('u_like_7d_sum', default_value=0.0)\n",
    "    u_click_avatar_7d_sum = fc.numeric_column('u_click_avatar_7d_sum', default_value=0.0)\n",
    "    u_forward_7d_sum = fc.numeric_column('u_forward_7d_sum', default_value=0.0)\n",
    "    u_comment_7d_sum = fc.numeric_column('u_comment_7d_sum', default_value=0.0)\n",
    "    u_follow_7d_sum = fc.numeric_column('u_follow_7d_sum', default_value=0.0)\n",
    "    u_favorite_7d_sum = fc.numeric_column('u_favorite_7d_sum', default_value=0.0)\n",
    "\n",
    "    i_read_comment_7d_sum = fc.numeric_column('i_read_comment_7d_sum', default_value=0.0)\n",
    "    i_like_7d_sum = fc.numeric_column('i_like_7d_sum', default_value=0.0)\n",
    "    i_click_avatar_7d_sum = fc.numeric_column('i_click_avatar_7d_sum', default_value=0.0)\n",
    "    i_forward_7d_sum = fc.numeric_column('i_forward_7d_sum', default_value=0.0)\n",
    "    i_comment_7d_sum = fc.numeric_column('i_comment_7d_sum', default_value=0.0)\n",
    "    i_follow_7d_sum = fc.numeric_column('i_follow_7d_sum', default_value=0.0)\n",
    "    i_favorite_7d_sum = fc.numeric_column('i_favorite_7d_sum', default_value=0.0)\n",
    "\n",
    "    c_user_author_read_comment_7d_sum = fc.numeric_column('c_user_author_read_comment_7d_sum', default_value=0.0)\n",
    "\n",
    "    dense_feature_columns += [videoplayseconds, u_read_comment_7d_sum, u_like_7d_sum, u_click_avatar_7d_sum,\n",
    "                              u_forward_7d_sum, u_comment_7d_sum, u_follow_7d_sum, u_favorite_7d_sum,\n",
    "                              i_read_comment_7d_sum, i_like_7d_sum, i_click_avatar_7d_sum, i_forward_7d_sum,\n",
    "                              i_comment_7d_sum, i_follow_7d_sum, i_favorite_7d_sum,\n",
    "                              c_user_author_read_comment_7d_sum]\n",
    "\n",
    "    # 类别特征\n",
    "    userid = fc.categorical_column_with_vocabulary_file('userid', os.path.join(vocabulary_dir, 'userid.txt'))\n",
    "    feedid = fc.categorical_column_with_vocabulary_file('feedid', os.path.join(vocabulary_dir, 'feedid.txt'))\n",
    "    device = fc.categorical_column_with_vocabulary_file('device', os.path.join(vocabulary_dir, 'device.txt'))\n",
    "    authorid = fc.categorical_column_with_vocabulary_file('authorid', os.path.join(vocabulary_dir, 'authorid.txt'))\n",
    "    bgm_song_id = fc.categorical_column_with_vocabulary_file('bgm_song_id', os.path.join(vocabulary_dir, 'bgm_song_id.txt'))\n",
    "    bgm_singer_id = fc.categorical_column_with_vocabulary_file('bgm_singer_id', os.path.join(vocabulary_dir, 'bgm_singer_id.txt'))\n",
    "    manual_tag_list = fc.categorical_column_with_vocabulary_file('manual_tag_list', os.path.join(vocabulary_dir, 'manual_tag_id.txt'))\n",
    "    his_read_comment_7d_seq = fc.categorical_column_with_vocabulary_file('his_read_comment_7d_seq', os.path.join(vocabulary_dir, 'feedid.txt'))\n",
    "\n",
    "    userid_emb = fc.embedding_column(userid, 16)\n",
    "    feedid_emb = fc.embedding_column(feedid, 16, combiner='mean')\n",
    "    device_emb = fc.embedding_column(device, 2)\n",
    "    authorid_emb = fc.embedding_column(authorid, 4)\n",
    "    bgm_song_id_emb = fc.embedding_column(bgm_song_id, 4)\n",
    "    bgm_singer_id_emb = fc.embedding_column(bgm_singer_id, 4)\n",
    "    manual_tag_id_emb = fc.embedding_column(manual_tag_list, 4, combiner='mean')\n",
    "\n",
    "    category_feature_columns += [userid_emb, device_emb, authorid_emb, bgm_song_id_emb, bgm_singer_id_emb, manual_tag_id_emb]\n",
    "    category_feature_columns += [feedid_emb]  # feedid_emb是list\n",
    "    \n",
    "    # label\n",
    "    label_feature_columns += [fc.numeric_column(task_name, default_value=0.0) for task_name in task_names]\n",
    "    \n",
    "    return dense_feature_columns, category_feature_columns, label_feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4590150c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_parser(serialized_example):\n",
    "    \"\"\"\n",
    "        批量解析Example\n",
    "    Args:\n",
    "        serialized_example:\n",
    "\n",
    "    Returns:\n",
    "        features, labels\n",
    "    \"\"\"\n",
    "    fea_columns = total_feature_columns\n",
    "    label_columns = label_feature_columns\n",
    "   \n",
    "    feature_spec = tf.feature_column.make_parse_example_spec(fea_columns + label_columns)\n",
    "    features = tf.io.parse_example(serialized_example, features=feature_spec)\n",
    "\n",
    "    labels = {task_name: features.pop(task_name) for task_name in task_names}\n",
    "\n",
    "    return features, labels\n",
    "\n",
    "def train_input_fn(filepath, example_parser, batch_size, num_epochs, shuffle_buffer_size):\n",
    "    \"\"\"\n",
    "        mmoe模型的input_fn\n",
    "    Args:\n",
    "        filepath (str): 训练集/验证集的路径\n",
    "        example_parser (function): 解析example的函数\n",
    "        batch_size (int): 每个batch样本大小\n",
    "        num_epochs (int): 训练轮数\n",
    "        shuffle_buffer_size (inr): shuffle时buffer的大小\n",
    "\n",
    "    Returns:\n",
    "        dataset\n",
    "    \"\"\"\n",
    "\n",
    "    dataset = tf.data.TFRecordDataset(filepath)\n",
    "    if shuffle_buffer_size > 0:\n",
    "        dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    dataset = dataset.repeat(num_epochs)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(example_parser, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.prefetch(1)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def eval_input_fn(filepath, example_parser, batch_size):\n",
    "    \"\"\"\n",
    "        mmoe模型的eval阶段input_fn\n",
    "    Args:\n",
    "        filepath (str): 训练集/验证集的路径\n",
    "        example_parser (function): 解析example的函数\n",
    "        batch_size (int): 每个batch样本大小\n",
    "\n",
    "    Returns:\n",
    "        dataset\n",
    "    \"\"\"\n",
    "\n",
    "    dataset = tf.data.TFRecordDataset(filepath)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(example_parser, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.prefetch(1)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae7bd07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def extraction_network(input, task_names, num_experts_per_task, num_experts_in_shared, expert_hidden_units, name):\n",
    "    \"\"\"\n",
    "        实现PLE模型中的extraction_network模块\n",
    "    Args:\n",
    "        input (tf.Tensor):  输入, shape=(B, input_dim)\n",
    "        task_names (list): 每个task的名字组合的list\n",
    "        num_experts_per_task (list): 每个任务的task专家个数\n",
    "        num_experts_in_shared (list): shared专家个数\n",
    "        expert_hidden_units (int): 专家维度\n",
    "        name (str): 传入tf.variable_scope的参数\n",
    "    Returns:\n",
    "        tf.Tensor, 输出, shape=(B, output_dim)\n",
    "    \"\"\"\n",
    "\n",
    "    # 最终输出\n",
    "    final_output = []\n",
    "\n",
    "    # 所有task专家和shared专家\n",
    "    all_experts = []\n",
    "\n",
    "    with tf.compat.v1.variable_scope(name):\n",
    "        # shared专家网络输出列表\n",
    "        shared_specific_experts = [tf.compat.v1.layers.dense(input,\n",
    "                                                   expert_hidden_units,\n",
    "                                                   activation=tf.nn.relu,\n",
    "                                                   name=f\"shared_expert_{i}\") for i in range(num_experts_in_shared)]\n",
    "        # (B, expert_hidden_units) * num_experts_in_shared\n",
    "\n",
    "        shared_specific_experts = [e[:, tf.newaxis, :] for e in shared_specific_experts]    # (B, 1, expert_hidden_units) * num_experts_in_shared\n",
    "        shared_specific_experts = tf.concat(shared_specific_experts, axis=1)    # (B, num_experts_in_shared, expert_hidden_units)\n",
    "\n",
    "        # 遍历每个任务的task专家数量, 与share专家组合\n",
    "        for task_name, num_experts_in_task in zip(task_names, num_experts_per_task):\n",
    "            # 每个任务的task专家网络输出列表\n",
    "            task_specific_experts = [tf.compat.v1.layers.dense(input,\n",
    "                                                     expert_hidden_units,\n",
    "                                                     activation=tf.nn.relu,\n",
    "                                                     name=f\"task_specific_expert_{task_name}_{i}\") for i in\n",
    "                                                          range(num_experts_in_task)]\n",
    "            # (B, expert_hidden_units) * num_experts_in_task\n",
    "\n",
    "            task_specific_experts = [e[:, tf.newaxis, :] for e in task_specific_experts]  # (B, 1, expert_hidden_units) * num_experts_in_task\n",
    "            task_specific_experts = tf.concat(task_specific_experts, axis=1)  # (B, num_experts_in_task, expert_hidden_units)\n",
    "            # 放入all_experts内, 后面用\n",
    "            all_experts.append(task_specific_experts)\n",
    "\n",
    "            combined_experts = tf.concat([task_specific_experts, shared_specific_experts], axis=1)\n",
    "            # (B, num_experts_in_task+num_experts_in_shared, expert_hidden_units)\n",
    "\n",
    "            # 门输出\n",
    "            gate = tf.compat.v1.layers.dense(input,\n",
    "                                   num_experts_in_task+num_experts_in_shared,\n",
    "                                   activation=tf.nn.softmax,\n",
    "                                   use_bias=False,  # 论文中省略了bias\n",
    "                                   name=f\"gate_{task_name}\")\n",
    "            # (B, num_experts_in_task+num_experts_in_shared)\n",
    "\n",
    "            gate = tf.expand_dims(gate, axis=-1)  # (B, num_experts_in_task+num_experts_in_shared, 1)\n",
    "            # 组合专家网络输出和每一个任务相关的门输出做矩阵乘法\n",
    "            task_output = tf.matmul(combined_experts, gate, transpose_a=True)  # (B, expert_hidden_units, 1)\n",
    "            task_output = tf.squeeze(task_output, axis=-1)  # (B, expert_hidden_units)\n",
    "            final_output.append(task_output)\n",
    "\n",
    "        # 所有专家组合\n",
    "        all_experts.append(shared_specific_experts)\n",
    "        all_experts = tf.concat(all_experts, axis=1)    # (B, sum(num_experts_per_task)+num_experts_in_shared, expert_hidden_units)\n",
    "        # 所有专家对应的门输出\n",
    "        all_gate = tf.compat.v1.layers.dense(input,\n",
    "                                   sum(num_experts_per_task)+num_experts_in_shared,\n",
    "                                   activation=tf.nn.softmax,\n",
    "                                   use_bias=False,  # 论文中省略了bias\n",
    "                                   name=f\"all_gate\")\n",
    "        # (B, sum(num_experts_per_task)+num_experts_in_shared)\n",
    "        all_gate = tf.expand_dims(all_gate, axis=-1)    # (B, sum(num_experts_per_task)+num_experts_in_shared), 1)\n",
    "        # 所有专家组合网络输出和对应门输出做矩阵乘法\n",
    "        all_output = tf.matmul(all_experts, all_gate, transpose_a=True)  # (B, expert_hidden_units, 1)\n",
    "        all_output = tf.squeeze(all_output, axis=-1)    # (B, expert_hidden_units)\n",
    "        # 添加到最终输出\n",
    "        final_output.append(all_output)\n",
    "\n",
    "    return tf.add_n(final_output)   # (B, expert_hidden_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd003aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:vocabulary_size = 19626 in userid is inferred from the number of elements in the vocabulary_file E:/Deep Learning/dataset/wechat_bigdata/vocabulary/userid.txt.\n",
      "INFO:tensorflow:vocabulary_size = 106444 in feedid is inferred from the number of elements in the vocabulary_file E:/Deep Learning/dataset/wechat_bigdata/vocabulary/feedid.txt.\n",
      "INFO:tensorflow:vocabulary_size = 2 in device is inferred from the number of elements in the vocabulary_file E:/Deep Learning/dataset/wechat_bigdata/vocabulary/device.txt.\n",
      "INFO:tensorflow:vocabulary_size = 18789 in authorid is inferred from the number of elements in the vocabulary_file E:/Deep Learning/dataset/wechat_bigdata/vocabulary/authorid.txt.\n",
      "INFO:tensorflow:vocabulary_size = 25159 in bgm_song_id is inferred from the number of elements in the vocabulary_file E:/Deep Learning/dataset/wechat_bigdata/vocabulary/bgm_song_id.txt.\n",
      "INFO:tensorflow:vocabulary_size = 17500 in bgm_singer_id is inferred from the number of elements in the vocabulary_file E:/Deep Learning/dataset/wechat_bigdata/vocabulary/bgm_singer_id.txt.\n",
      "INFO:tensorflow:vocabulary_size = 350 in manual_tag_list is inferred from the number of elements in the vocabulary_file E:/Deep Learning/dataset/wechat_bigdata/vocabulary/manual_tag_id.txt.\n",
      "INFO:tensorflow:vocabulary_size = 106444 in his_read_comment_7d_seq is inferred from the number of elements in the vocabulary_file E:/Deep Learning/dataset/wechat_bigdata/vocabulary/feedid.txt.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'authorid': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x1f3415562e0>,\n",
       "  'bgm_singer_id': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x1f341556160>,\n",
       "  'bgm_song_id': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x1f3415560a0>,\n",
       "  'device': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x1f3415569d0>,\n",
       "  'feedid': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x1f341556ee0>,\n",
       "  'manual_tag_list': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x1f3415756d0>,\n",
       "  'userid': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x1f3415753a0>,\n",
       "  'c_user_author_read_comment_7d_sum': <tf.Tensor: shape=(1024, 1), dtype=float32, numpy=\n",
       "  array([[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]], dtype=float32)>,\n",
       "  'i_click_avatar_7d_sum': <tf.Tensor: shape=(1024, 1), dtype=float32, numpy=\n",
       "  array([[1.3862944],\n",
       "         [0.6931472],\n",
       "         [0.6931472],\n",
       "         ...,\n",
       "         [0.6931472],\n",
       "         [1.0986123],\n",
       "         [2.1972246]], dtype=float32)>,\n",
       "  'i_comment_7d_sum': <tf.Tensor: shape=(1024, 1), dtype=float32, numpy=\n",
       "  array([[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]], dtype=float32)>,\n",
       "  'i_favorite_7d_sum': <tf.Tensor: shape=(1024, 1), dtype=float32, numpy=\n",
       "  array([[0.       ],\n",
       "         [0.       ],\n",
       "         [1.3862944],\n",
       "         ...,\n",
       "         [0.       ],\n",
       "         [0.       ],\n",
       "         [0.       ]], dtype=float32)>,\n",
       "  'i_follow_7d_sum': <tf.Tensor: shape=(1024, 1), dtype=float32, numpy=\n",
       "  array([[0.       ],\n",
       "         [0.       ],\n",
       "         [0.6931472],\n",
       "         ...,\n",
       "         [0.       ],\n",
       "         [0.6931472],\n",
       "         [0.6931472]], dtype=float32)>,\n",
       "  'i_forward_7d_sum': <tf.Tensor: shape=(1024, 1), dtype=float32, numpy=\n",
       "  array([[1.0986123],\n",
       "         [0.       ],\n",
       "         [0.6931472],\n",
       "         ...,\n",
       "         [0.       ],\n",
       "         [1.0986123],\n",
       "         [0.       ]], dtype=float32)>,\n",
       "  'i_like_7d_sum': <tf.Tensor: shape=(1024, 1), dtype=float32, numpy=\n",
       "  array([[2.4849067],\n",
       "         [1.9459101],\n",
       "         [3.2580965],\n",
       "         ...,\n",
       "         [0.       ],\n",
       "         [2.7080503],\n",
       "         [1.0986123]], dtype=float32)>,\n",
       "  'i_read_comment_7d_sum': <tf.Tensor: shape=(1024, 1), dtype=float32, numpy=\n",
       "  array([[3.6109178],\n",
       "         [3.583519 ],\n",
       "         [4.158883 ],\n",
       "         ...,\n",
       "         [0.       ],\n",
       "         [2.6390574],\n",
       "         [2.3025851]], dtype=float32)>,\n",
       "  'u_click_avatar_7d_sum': <tf.Tensor: shape=(1024, 1), dtype=float32, numpy=\n",
       "  array([[0.       ],\n",
       "         [0.       ],\n",
       "         [0.       ],\n",
       "         ...,\n",
       "         [0.6931472],\n",
       "         [0.6931472],\n",
       "         [0.       ]], dtype=float32)>,\n",
       "  'u_comment_7d_sum': <tf.Tensor: shape=(1024, 1), dtype=float32, numpy=\n",
       "  array([[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]], dtype=float32)>,\n",
       "  'u_favorite_7d_sum': <tf.Tensor: shape=(1024, 1), dtype=float32, numpy=\n",
       "  array([[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]], dtype=float32)>,\n",
       "  'u_follow_7d_sum': <tf.Tensor: shape=(1024, 1), dtype=float32, numpy=\n",
       "  array([[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]], dtype=float32)>,\n",
       "  'u_forward_7d_sum': <tf.Tensor: shape=(1024, 1), dtype=float32, numpy=\n",
       "  array([[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]], dtype=float32)>,\n",
       "  'u_like_7d_sum': <tf.Tensor: shape=(1024, 1), dtype=float32, numpy=\n",
       "  array([[0.6931472],\n",
       "         [1.3862944],\n",
       "         [1.9459101],\n",
       "         ...,\n",
       "         [2.6390574],\n",
       "         [0.6931472],\n",
       "         [4.356709 ]], dtype=float32)>,\n",
       "  'u_read_comment_7d_sum': <tf.Tensor: shape=(1024, 1), dtype=float32, numpy=\n",
       "  array([[0.       ],\n",
       "         [2.1972246],\n",
       "         [3.8918202],\n",
       "         ...,\n",
       "         [4.158883 ],\n",
       "         [0.       ],\n",
       "         [3.5263605]], dtype=float32)>,\n",
       "  'videoplayseconds': <tf.Tensor: shape=(1024, 1), dtype=float32, numpy=\n",
       "  array([[2.],\n",
       "         [4.],\n",
       "         [2.],\n",
       "         ...,\n",
       "         [3.],\n",
       "         [3.],\n",
       "         [4.]], dtype=float32)>},\n",
       " {'read_comment': <tf.Tensor: shape=(1024, 1), dtype=float32, numpy=\n",
       "  array([[0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]], dtype=float32)>,\n",
       "  'like': <tf.Tensor: shape=(1024, 1), dtype=float32, numpy=\n",
       "  array([[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]], dtype=float32)>,\n",
       "  'click_avatar': <tf.Tensor: shape=(1024, 1), dtype=float32, numpy=\n",
       "  array([[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]], dtype=float32)>})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global total_feature_columns, label_feature_columns\n",
    "dense_feature_columns, category_feature_columns, label_feature_columns = create_feature_columns()\n",
    "\n",
    "total_feature_columns = dense_feature_columns + category_feature_columns\n",
    "\n",
    "dataset = train_input_fn('E:/Deep Learning/dataset/wechat_bigdata/tfrecord/train.tfrecord',\n",
    "                        example_parser,\n",
    "                        batch_size,\n",
    "                        num_epochs,\n",
    "                        shuffle_buffer_size\n",
    "                        )\n",
    "\n",
    "one_element = tf.compat.v1.data.make_one_shot_iterator(dataset).get_next()\n",
    "\n",
    "one_element\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dea60173",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ple_model_fn(features, labels, mode, params):\n",
    "    \"\"\"\n",
    "    ple模型的model_fn\n",
    "    Args:\n",
    "        features (dict): input_fn的第一个返回值, 模型输入样本特征\n",
    "        labels (dict): input_fn的第二个返回值, 样本标签\n",
    "        mode: tf.estimator.ModeKeys\n",
    "        params (dict): 模型超参数\n",
    "\n",
    "    Returns:\n",
    "        tf.estimator.EstimatorSpec\n",
    "    \"\"\"\n",
    "\n",
    "    # 连续特征\n",
    "    with tf.compat.v1.variable_scope(\"dense_input\"):\n",
    "        dense_input = tf.compat.v1.feature_column.input_layer(features, params[\"dense_feature_columns\"])\n",
    "\n",
    "    \n",
    "    print(dense_input)\n",
    "    # 类别特征\n",
    "    with tf.compat.v1.variable_scope(\"category_input\"):\n",
    "        category_input = tf.compat.v1.feature_column.input_layer(features, params[\"category_feature_columns\"])\n",
    "\n",
    "    # concat all\n",
    "    concat_all_input = tf.concat([dense_input, category_input], axis=-1)\n",
    "    \n",
    "    \n",
    "    # extract network\n",
    "    input = concat_all_input\n",
    "    for i in range(params[\"num_extract_network\"]):\n",
    "        extract_network_output = extraction_network(input=input,\n",
    "                                                    task_names=params[\"task_names\"],\n",
    "                                                    num_experts_per_task=params[\"num_experts_per_task\"],\n",
    "                                                    num_experts_in_shared=params[\"num_experts_in_shared\"],\n",
    "                                                    expert_hidden_units=params[\"expert_hidden_units\"],\n",
    "                                                    name=f\"extract_network_{i}\")\n",
    "        input = extract_network_output\n",
    "\n",
    "    # 进入task tower的最后一层\n",
    "    task_tower_inputs = []   # 存放最后任务塔的输入\n",
    "    # shared experts\n",
    "    with tf.compat.v1.variable_scope(\"shared_experts_final\"):\n",
    "        # shared专家网络输出列表\n",
    "        shared_specific_experts_final = [tf.compat.v1.layers.dense(input,\n",
    "                                                         params[\"expert_hidden_units\"],\n",
    "                                                         activation=tf.nn.relu,\n",
    "                                                         name=f\"shared_expert_final_{i}\") for i in range(params[\"num_experts_in_shared\"])]\n",
    "        # (B, expert_hidden_units) * num_experts_in_shared\n",
    "\n",
    "        shared_specific_experts_final = [e[:, tf.newaxis, :] for e in\n",
    "                                         shared_specific_experts_final]  # (B, 1, expert_hidden_units) * num_experts_in_shared\n",
    "        shared_specific_experts_final = tf.concat(shared_specific_experts_final,\n",
    "                                            axis=1)  # (B, num_experts_in_shared, expert_hidden_units)\n",
    "\n",
    "    # task specific experts\n",
    "    with tf.compat.v1.variable_scope(\"task_specific_experts_final\"):\n",
    "        # 每个任务的task专家网络输出列表\n",
    "        for task_name, num_experts_in_task in zip(params[\"task_names\"], params[\"num_experts_per_task\"]):\n",
    "            task_specific_experts_final = [tf.compat.v1.layers.dense(input,\n",
    "                                                           params[\"expert_hidden_units\"],\n",
    "                                                           activation=tf.nn.relu,\n",
    "                                                           name=f\"task_specific_expert_final_{task_name}_{i}\") for i in\n",
    "                                                                range(num_experts_in_task)]\n",
    "            # (B, expert_hidden_units) * num_experts_in_task\n",
    "\n",
    "            task_specific_experts_final = [e[:, tf.newaxis, :] for e in task_specific_experts_final]  # (B, 1, expert_hidden_units) * num_experts_in_task\n",
    "            task_specific_experts_final = tf.concat(task_specific_experts_final, axis=1)  # (B, num_experts_in_task, expert_hidden_units)\n",
    "\n",
    "            # 与shared专家组合\n",
    "            combined_experts = tf.concat([task_specific_experts_final, shared_specific_experts_final], axis=1)\n",
    "            # (B, num_experts_in_task+num_experts_in_shared, expert_hidden_units)\n",
    "            with tf.compat.v1.variable_scope(\"task_gate_final\"):\n",
    "                gate = tf.compat.v1.layers.dense(input,\n",
    "                                       num_experts_in_task + params[\"num_experts_in_shared\"],\n",
    "                                       activation=tf.nn.softmax,\n",
    "                                       use_bias=False,  # 论文中省略了bias\n",
    "                                       name=f\"gate_final_{task_name}\")\n",
    "                # (B, num_experts_in_task+num_experts_in_shared)\n",
    "                gate = tf.expand_dims(gate, axis=-1)  # (B, num_experts_in_task+num_experts_in_shared, 1)\n",
    "                # 组合专家网络输出和每一个任务相关的门输出做矩阵乘法, 结果作为任务tower的输入\n",
    "                task_tower_input = tf.matmul(combined_experts, gate, transpose_a=True)  # (B, expert_hidden_units, 1)\n",
    "                task_tower_input = tf.squeeze(task_tower_input, axis=-1)  # (B, expert_hidden_units)\n",
    "                task_tower_inputs.append(task_tower_input)  # (B, expert_hidden_units) * num_task\n",
    "\n",
    "    # 任务塔\n",
    "    with tf.compat.v1.variable_scope(\"tower\"):\n",
    "        logit_list = [tower_layer(x=x,\n",
    "                                  hidden_units=params[\"hidden_units\"],\n",
    "                                  mode=mode,\n",
    "                                  batch_norm=params[\"batch_norm\"],\n",
    "                                  dropout_rate=params[\"dropout_rate\"],\n",
    "                                  name=task_name) for x, task_name in zip(task_tower_inputs, params[\"task_names\"])]\n",
    "        # (B, 1) * num_tasks\n",
    "\n",
    "        \n",
    "    # -----定义PREDICT阶段行为-----\n",
    "    prediction_list = [tf.sigmoid(ple_output, name=f\"prediction_{task_name}\") for ple_output, task_name in zip(logit_list, params[\"task_names\"])]\n",
    "\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = {\n",
    "            f\"{task_name}_probabilities\": prediction for task_name, prediction in zip(task_names, prediction_list)\n",
    "        }\n",
    "        export_outputs = {\n",
    "            'prediction': tf.estimator.export.PredictOutput(predictions)\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=predictions, export_outputs=export_outputs)\n",
    "    # -----定义完毕-----\n",
    "\n",
    "    losses = [tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=labels[task_name], logits=logit), name=f\"loss_{task_name}\")\n",
    "              for logit, task_name in zip(logit_list, task_names)]\n",
    "    total_loss = tf.add_n(losses)\n",
    "\n",
    "    accuracy_list = [tf.compat.v1.metrics.accuracy(labels=labels[task_name], predictions=tf.compat.v1.to_float(tf.greater_equal(prediction, 0.5)))\n",
    "                     for task_name, prediction in zip(task_names, prediction_list)]\n",
    "    auc_list = [tf.compat.v1.metrics.auc(labels=labels[task_name], predictions=prediction)\n",
    "                for task_name, prediction in zip(task_names, prediction_list)]\n",
    "\n",
    "    # -----定义EVAL阶段行为-----\n",
    "    auc_metrics = {f\"eval_{task_name}_auc\": auc for task_name, auc in zip(task_names, auc_list)}\n",
    "    accuracy_metrics = {f\"eval_{task_name}_accuracy\": accuracy for task_name, accuracy in zip(task_names, accuracy_list)}\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return tf.estimator.EstimatorSpec(mode, loss=total_loss, eval_metric_ops={**accuracy_metrics, **auc_metrics})\n",
    "    # -----定义完毕-----\n",
    "\n",
    "    optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=params[\"learning_rate\"], beta1=0.9,\n",
    "                                       beta2=0.999, epsilon=1e-8)\n",
    "    update_ops = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(update_ops):\n",
    "        train_op = optimizer.minimize(loss=total_loss, global_step=tf.compat.v1.train.get_global_step())\n",
    "\n",
    "    # -----定义TRAIN阶段行为-----\n",
    "    assert mode == tf.estimator.ModeKeys.TRAIN\n",
    "\n",
    "    # tensorboard收集\n",
    "    for task_name, auc in zip(task_names, auc_list):\n",
    "        tf.summary.scalar(f\"train_{task_name}_auc\", auc[1])\n",
    "    for task_name, accuracy in zip(task_names, accuracy_list):\n",
    "        tf.summary.scalar(f\"train_{task_name}_accuracy\", accuracy[1])\n",
    "\n",
    "    # 训练log打印\n",
    "    # 观测loss\n",
    "    loss_log = {f\"train_{task_name}_loss\": loss for task_name, loss in zip(task_names, losses)}\n",
    "    # 观测训练auc\n",
    "    auc_log = {f\"train_{task_name}_auc\": auc[1] for task_name, auc in zip(task_names, auc_list)}\n",
    "    # 观测gate输出\n",
    "    # gate_log = {f\"{task_name}_gate_expert_weight\": gate for task_name, gate, in zip(task_names, gates)}\n",
    "\n",
    "    loss_log_hook = tf.compat.v1.train.LoggingTensorHook(\n",
    "        loss_log,\n",
    "        every_n_iter=100\n",
    "    )\n",
    "    auc_log_hook = tf.compat.v1.train.LoggingTensorHook(\n",
    "        auc_log,\n",
    "        every_n_iter=100\n",
    "    )\n",
    "#     gate_log_hook = tf.compat.v1.train.LoggingTensorHook(\n",
    "#         gate_log,\n",
    "#         every_n_iter=100\n",
    "#     )\n",
    "    return tf.estimator.EstimatorSpec(mode, loss=total_loss, train_op=train_op,\n",
    "                                      training_hooks=[loss_log_hook, auc_log_hook])\n",
    "    # -----定义完毕-----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8c9ab7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:vocabulary_size = 19626 in userid is inferred from the number of elements in the vocabulary_file E:/Deep Learning/dataset/wechat_bigdata/vocabulary/userid.txt.\n",
      "INFO:tensorflow:vocabulary_size = 106444 in feedid is inferred from the number of elements in the vocabulary_file E:/Deep Learning/dataset/wechat_bigdata/vocabulary/feedid.txt.\n",
      "INFO:tensorflow:vocabulary_size = 2 in device is inferred from the number of elements in the vocabulary_file E:/Deep Learning/dataset/wechat_bigdata/vocabulary/device.txt.\n",
      "INFO:tensorflow:vocabulary_size = 18789 in authorid is inferred from the number of elements in the vocabulary_file E:/Deep Learning/dataset/wechat_bigdata/vocabulary/authorid.txt.\n",
      "INFO:tensorflow:vocabulary_size = 25159 in bgm_song_id is inferred from the number of elements in the vocabulary_file E:/Deep Learning/dataset/wechat_bigdata/vocabulary/bgm_song_id.txt.\n",
      "INFO:tensorflow:vocabulary_size = 17500 in bgm_singer_id is inferred from the number of elements in the vocabulary_file E:/Deep Learning/dataset/wechat_bigdata/vocabulary/bgm_singer_id.txt.\n",
      "INFO:tensorflow:vocabulary_size = 350 in manual_tag_list is inferred from the number of elements in the vocabulary_file E:/Deep Learning/dataset/wechat_bigdata/vocabulary/manual_tag_id.txt.\n",
      "INFO:tensorflow:vocabulary_size = 106444 in his_read_comment_7d_seq is inferred from the number of elements in the vocabulary_file E:/Deep Learning/dataset/wechat_bigdata/vocabulary/feedid.txt.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"训练入口\"\"\"\n",
    "\n",
    "global total_feature_columns, label_feature_columns\n",
    "dense_feature_columns, category_feature_columns, label_feature_columns = create_feature_columns()\n",
    "total_feature_columns = dense_feature_columns + category_feature_columns\n",
    "\n",
    "params = {\n",
    "             \"dense_feature_columns\": dense_feature_columns,\n",
    "             \"category_feature_columns\": category_feature_columns,\n",
    "             \"hidden_units\": hidden_units,\n",
    "             \"dropout_rate\": dropout_rate,\n",
    "             \"batch_norm\": batch_norm,\n",
    "             \"learning_rate\": learning_rate,\n",
    "             # \"num_experts\": num_experts,\n",
    "             \"num_tasks\": num_tasks,\n",
    "             \"expert_hidden_units\": expert_hidden_units,\n",
    "             \"task_names\": task_names,\n",
    "             \"num_extract_network\": num_extract_network,\n",
    "             \"num_experts_per_task\": [int(x) for x in num_experts_per_task],\n",
    "             \"num_experts_in_shared\": num_experts_in_shared,\n",
    "         }\n",
    "# print(params)\n",
    "\n",
    "# 任务数要和任务名列表长度一致\n",
    "assert params[\"num_tasks\"] == len(params[\"task_names\"]), \"num_tasks must equals length of task_names\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd8fc822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'model\\\\model_dir\\\\PLE', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 1000 or save_checkpoints_secs None.\n",
      "WARNING:tensorflow:From C:\\Users\\46581\\miniconda3\\lib\\site-packages\\tensorflow\\python\\training\\training_util.py:396: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From C:\\Users\\46581\\miniconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py:198: NumericColumn._get_dense_tensor (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From C:\\Users\\46581\\miniconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py:2188: NumericColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From C:\\Users\\46581\\miniconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py:202: NumericColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "Tensor(\"dense_input/input_layer/concat:0\", shape=(None, 16), dtype=float32)\n",
      "WARNING:tensorflow:From C:\\Users\\46581\\miniconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py:198: EmbeddingColumn._get_dense_tensor (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From C:\\Users\\46581\\miniconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:3073: VocabularyFileCategoricalColumn._get_sparse_tensors (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From C:\\Users\\46581\\miniconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py:2188: VocabularyFileCategoricalColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From C:\\Users\\46581\\miniconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:3014: VocabularyFileCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From C:\\Users\\46581\\miniconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py:202: EmbeddingColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\46581\\AppData\\Local\\Temp/ipykernel_6220/2769817402.py:26: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  shared_specific_experts = [tf.compat.v1.layers.dense(input,\n",
      "C:\\Users\\46581\\miniconda3\\lib\\site-packages\\keras\\legacy_tf_layers\\core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  return layer.apply(inputs)\n",
      "C:\\Users\\46581\\AppData\\Local\\Temp/ipykernel_6220/2769817402.py:38: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  task_specific_experts = [tf.compat.v1.layers.dense(input,\n",
      "C:\\Users\\46581\\AppData\\Local\\Temp/ipykernel_6220/2769817402.py:54: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  gate = tf.compat.v1.layers.dense(input,\n",
      "C:\\Users\\46581\\AppData\\Local\\Temp/ipykernel_6220/2769817402.py:71: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  all_gate = tf.compat.v1.layers.dense(input,\n",
      "C:\\Users\\46581\\AppData\\Local\\Temp/ipykernel_6220/2289478039.py:44: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  shared_specific_experts_final = [tf.compat.v1.layers.dense(input,\n",
      "C:\\Users\\46581\\AppData\\Local\\Temp/ipykernel_6220/2289478039.py:59: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  task_specific_experts_final = [tf.compat.v1.layers.dense(input,\n",
      "C:\\Users\\46581\\AppData\\Local\\Temp/ipykernel_6220/2289478039.py:73: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  gate = tf.compat.v1.layers.dense(input,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\46581\\miniconda3\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py:532: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:20: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "<string>:22: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n",
      "C:\\Users\\46581\\miniconda3\\lib\\site-packages\\keras\\legacy_tf_layers\\core.py:413: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  return layer.apply(inputs, training=training)\n",
      "<string>:24: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "C:\\Users\\46581\\miniconda3\\lib\\site-packages\\keras\\legacy_tf_layers\\normalization.py:463: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  return layer.apply(inputs, training=training)\n",
      "<string>:26: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\46581\\miniconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From C:\\Users\\46581\\AppData\\Local\\Temp/ipykernel_6220/2289478039.py:116: auc (from tensorflow.python.ops.metrics_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The value of AUC returned by this may race with the update so this is deprecated. Please use tf.keras.metrics.AUC instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into model\\model_dir\\PLE\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 2.735826, step = 0\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.933015, train_like_loss = 0.9798341, train_read_comment_loss = 0.82297695\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.82681024, train_like_auc = 0.4157327, train_read_comment_auc = 0.6769942\n",
      "INFO:tensorflow:global_step/sec: 3.3537\n",
      "INFO:tensorflow:loss = 0.24683607, step = 100 (29.818 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.03811363, train_like_loss = 0.1064769, train_read_comment_loss = 0.10224554 (29.819 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.46954662, train_like_auc = 0.5803264, train_read_comment_auc = 0.71473104 (29.819 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.40277\n",
      "INFO:tensorflow:loss = 0.28386083, step = 200 (29.388 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.033931777, train_like_loss = 0.11196183, train_read_comment_loss = 0.13796723 (29.388 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.58717704, train_like_auc = 0.6160474, train_read_comment_auc = 0.7425563 (29.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.87634\n",
      "INFO:tensorflow:loss = 0.24855077, step = 300 (34.767 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.033591643, train_like_loss = 0.11757295, train_read_comment_loss = 0.09738618 (34.767 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.6078703, train_like_auc = 0.64816743, train_read_comment_auc = 0.7795716 (34.767 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.20156\n",
      "INFO:tensorflow:loss = 0.2173742, step = 400 (31.236 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.050143085, train_like_loss = 0.065296225, train_read_comment_loss = 0.101934895 (31.236 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.61506164, train_like_auc = 0.6734884, train_read_comment_auc = 0.81821156 (31.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.27085\n",
      "INFO:tensorflow:loss = 0.26033005, step = 500 (30.571 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.032806855, train_like_loss = 0.17443702, train_read_comment_loss = 0.053086188 (30.571 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.66226065, train_like_auc = 0.69253206, train_read_comment_auc = 0.83859384 (30.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.24931\n",
      "INFO:tensorflow:loss = 0.20616344, step = 600 (30.777 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.034648195, train_like_loss = 0.08976006, train_read_comment_loss = 0.081755176 (30.778 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.6952938, train_like_auc = 0.70594823, train_read_comment_auc = 0.8534145 (30.777 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.28496\n",
      "INFO:tensorflow:loss = 0.26528198, step = 700 (30.441 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.04550852, train_like_loss = 0.08915079, train_read_comment_loss = 0.13062266 (30.440 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.7063638, train_like_auc = 0.7108643, train_read_comment_auc = 0.8564191 (30.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.12107\n",
      "INFO:tensorflow:loss = 0.2478455, step = 800 (32.042 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.041203022, train_like_loss = 0.11242949, train_read_comment_loss = 0.09421298 (32.042 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.7123248, train_like_auc = 0.7258794, train_read_comment_auc = 0.8659406 (32.041 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.15117\n",
      "INFO:tensorflow:loss = 0.27147368, step = 900 (31.732 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.047421277, train_like_loss = 0.14604458, train_read_comment_loss = 0.07800782 (31.732 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.72216684, train_like_auc = 0.72127396, train_read_comment_auc = 0.8716467 (31.732 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1000...\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into model\\model_dir\\PLE\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1000...\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Tensor(\"dense_input/input_layer/concat:0\", shape=(None, 16), dtype=float32)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-04-02T15:56:29\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model\\model_dir\\PLE\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 49.18196s\n",
      "INFO:tensorflow:Finished evaluation at 2023-04-02-15:57:18\n",
      "INFO:tensorflow:Saving dict for global step 1000: eval_click_avatar_accuracy = 0.9906968, eval_click_avatar_auc = 0.7975482, eval_like_accuracy = 0.9761295, eval_like_auc = 0.77042276, eval_read_comment_accuracy = 0.9664371, eval_read_comment_auc = 0.9069346, global_step = 1000, loss = 0.24469762\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: model\\model_dir\\PLE\\model.ckpt-1000\n",
      "INFO:tensorflow:Loading best metric from event files.\n",
      "WARNING:tensorflow:From C:\\Users\\46581\\miniconda3\\lib\\site-packages\\tensorflow\\python\\summary\\summary_iterator.py:27: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "INFO:tensorflow:Performing best model export.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Tensor(\"dense_input/input_layer/concat:0\", shape=(None, 16), dtype=float32)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "WARNING:tensorflow:From C:\\Users\\46581\\miniconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\signature_def_utils_impl.py:203: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['prediction', 'serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from model\\model_dir\\PLE\\model.ckpt-1000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:Assets written to: model\\model_dir\\PLE\\export\\best_exporter\\temp-1680422238\\assets\n",
      "INFO:tensorflow:SavedModel written to: model\\model_dir\\PLE\\export\\best_exporter\\temp-1680422238\\saved_model.pb\n",
      "INFO:tensorflow:global_step/sec: 1.16528\n",
      "INFO:tensorflow:loss = 0.16560042, step = 1000 (85.816 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.017832413, train_like_loss = 0.065747015, train_read_comment_loss = 0.08202098 (85.816 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.72800994, train_like_auc = 0.7338298, train_read_comment_auc = 0.87621945 (85.817 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.24335\n",
      "INFO:tensorflow:loss = 0.3182807, step = 1100 (30.836 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.0743101, train_like_loss = 0.12988058, train_read_comment_loss = 0.114090025 (30.836 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.7187499, train_like_auc = 0.7326807, train_read_comment_auc = 0.87589693 (30.835 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.25576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.2415678, step = 1200 (30.711 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.05115383, train_like_loss = 0.08327815, train_read_comment_loss = 0.10713582 (30.710 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.717052, train_like_auc = 0.7402016, train_read_comment_auc = 0.87692577 (30.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.30946\n",
      "INFO:tensorflow:loss = 0.22800916, step = 1300 (30.216 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.03659078, train_like_loss = 0.06970894, train_read_comment_loss = 0.121709436 (30.217 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.72569597, train_like_auc = 0.7439571, train_read_comment_auc = 0.8759414 (30.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.30156\n",
      "INFO:tensorflow:loss = 0.22917391, step = 1400 (30.289 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.031449564, train_like_loss = 0.10078922, train_read_comment_loss = 0.09693514 (30.288 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.733451, train_like_auc = 0.7552982, train_read_comment_auc = 0.8751159 (30.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.20331\n",
      "INFO:tensorflow:loss = 0.21176583, step = 1500 (31.219 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.05160611, train_like_loss = 0.07992265, train_read_comment_loss = 0.08023706 (31.220 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.7480766, train_like_auc = 0.7517443, train_read_comment_auc = 0.87823564 (31.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.19771\n",
      "INFO:tensorflow:loss = 0.20011562, step = 1600 (31.271 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.035232976, train_like_loss = 0.0978184, train_read_comment_loss = 0.06706425 (31.271 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.7510716, train_like_auc = 0.7647941, train_read_comment_auc = 0.88291824 (31.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.27382\n",
      "INFO:tensorflow:loss = 0.1924634, step = 1700 (30.545 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.04367312, train_like_loss = 0.06885579, train_read_comment_loss = 0.079934485 (30.545 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.7522771, train_like_auc = 0.7673445, train_read_comment_auc = 0.8834367 (30.545 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.30849\n",
      "INFO:tensorflow:loss = 0.23887986, step = 1800 (30.225 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.01773974, train_like_loss = 0.13264191, train_read_comment_loss = 0.088498205 (30.225 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.75758076, train_like_auc = 0.7702575, train_read_comment_auc = 0.88550764 (30.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.1862\n",
      "INFO:tensorflow:loss = 0.2364855, step = 1900 (31.387 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.062255878, train_like_loss = 0.08729864, train_read_comment_loss = 0.086930975 (31.386 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.74808663, train_like_auc = 0.7691088, train_read_comment_auc = 0.8878298 (31.387 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2000...\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into model\\model_dir\\PLE\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2000...\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 3.12257\n",
      "INFO:tensorflow:loss = 0.25443882, step = 2000 (32.023 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.051307037, train_like_loss = 0.13601173, train_read_comment_loss = 0.06712005 (32.023 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.75360346, train_like_auc = 0.77358705, train_read_comment_auc = 0.88866097 (32.023 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.29403\n",
      "INFO:tensorflow:loss = 0.17747256, step = 2100 (30.358 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.0053767376, train_like_loss = 0.0937794, train_read_comment_loss = 0.07831641 (30.359 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.757756, train_like_auc = 0.77334607, train_read_comment_auc = 0.8894228 (30.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.16206\n",
      "INFO:tensorflow:loss = 0.22254395, step = 2200 (31.625 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.01678401, train_like_loss = 0.093291424, train_read_comment_loss = 0.11246851 (31.624 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.7567357, train_like_auc = 0.7733714, train_read_comment_auc = 0.8894116 (31.624 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.25198\n",
      "INFO:tensorflow:loss = 0.24223752, step = 2300 (30.753 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.029309543, train_like_loss = 0.08950129, train_read_comment_loss = 0.12342669 (30.754 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.759278, train_like_auc = 0.77153724, train_read_comment_auc = 0.8925895 (30.754 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.2356\n",
      "INFO:tensorflow:loss = 0.24475974, step = 2400 (30.904 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.044509314, train_like_loss = 0.07862458, train_read_comment_loss = 0.12162585 (30.904 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.75384307, train_like_auc = 0.77399606, train_read_comment_auc = 0.89174044 (30.904 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.20329\n",
      "INFO:tensorflow:loss = 0.21757916, step = 2500 (31.219 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.03666798, train_like_loss = 0.099424526, train_read_comment_loss = 0.08148664 (31.219 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.759717, train_like_auc = 0.77879256, train_read_comment_auc = 0.89194757 (31.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.0544\n",
      "INFO:tensorflow:loss = 0.2558472, step = 2600 (32.739 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.041835092, train_like_loss = 0.12089871, train_read_comment_loss = 0.0931134 (32.738 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.75812554, train_like_auc = 0.78003585, train_read_comment_auc = 0.8929833 (32.739 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.16676\n",
      "INFO:tensorflow:loss = 0.2300018, step = 2700 (31.580 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.034396373, train_like_loss = 0.12555307, train_read_comment_loss = 0.07005235 (31.581 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.7594247, train_like_auc = 0.7754002, train_read_comment_auc = 0.8947392 (31.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.14692\n",
      "INFO:tensorflow:loss = 0.2778379, step = 2800 (31.775 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.06502551, train_like_loss = 0.09368351, train_read_comment_loss = 0.11912889 (31.775 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.7575493, train_like_auc = 0.7756956, train_read_comment_auc = 0.8948551 (31.775 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.14977\n",
      "INFO:tensorflow:loss = 0.22792777, step = 2900 (31.748 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.0141252205, train_like_loss = 0.09661361, train_read_comment_loss = 0.11718895 (31.749 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.7604283, train_like_auc = 0.77609974, train_read_comment_auc = 0.8946526 (31.748 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 3000...\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into model\\model_dir\\PLE\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 3000...\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Tensor(\"dense_input/input_layer/concat:0\", shape=(None, 16), dtype=float32)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-04-02T16:07:46\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model\\model_dir\\PLE\\model.ckpt-3000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 47.06610s\n",
      "INFO:tensorflow:Finished evaluation at 2023-04-02-16:08:33\n",
      "INFO:tensorflow:Saving dict for global step 3000: eval_click_avatar_accuracy = 0.99254066, eval_click_avatar_auc = 0.7857521, eval_like_accuracy = 0.976228, eval_like_auc = 0.79572666, eval_read_comment_accuracy = 0.96701014, eval_read_comment_auc = 0.9155987, global_step = 3000, loss = 0.22973163\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3000: model\\model_dir\\PLE\\model.ckpt-3000\n",
      "INFO:tensorflow:Performing best model export.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Tensor(\"dense_input/input_layer/concat:0\", shape=(None, 16), dtype=float32)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['prediction', 'serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from model\\model_dir\\PLE\\model.ckpt-3000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:Assets written to: model\\model_dir\\PLE\\export\\best_exporter\\temp-1680422913\\assets\n",
      "INFO:tensorflow:SavedModel written to: model\\model_dir\\PLE\\export\\best_exporter\\temp-1680422913\\saved_model.pb\n",
      "INFO:tensorflow:global_step/sec: 1.20422\n",
      "INFO:tensorflow:loss = 0.20974736, step = 3000 (83.044 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.0139308665, train_like_loss = 0.10329427, train_read_comment_loss = 0.092522226 (83.042 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.76506364, train_like_auc = 0.77761084, train_read_comment_auc = 0.89514816 (83.043 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.2852\n",
      "INFO:tensorflow:loss = 0.2062815, step = 3100 (30.439 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.035456702, train_like_loss = 0.08787447, train_read_comment_loss = 0.082950324 (30.440 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.76999426, train_like_auc = 0.7769552, train_read_comment_auc = 0.89580137 (30.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.24314\n",
      "INFO:tensorflow:loss = 0.2724951, step = 3200 (30.833 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.046987757, train_like_loss = 0.12047689, train_read_comment_loss = 0.10503046 (30.832 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.767407, train_like_auc = 0.78069377, train_read_comment_auc = 0.8950072 (30.833 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.16631\n",
      "INFO:tensorflow:loss = 0.21906768, step = 3300 (31.583 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.033573978, train_like_loss = 0.109446585, train_read_comment_loss = 0.07604711 (31.584 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.76590717, train_like_auc = 0.78146183, train_read_comment_auc = 0.8973679 (31.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.1826\n",
      "INFO:tensorflow:loss = 0.21780863, step = 3400 (31.422 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.033610366, train_like_loss = 0.06146685, train_read_comment_loss = 0.12273141 (31.422 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.7692458, train_like_auc = 0.7823548, train_read_comment_auc = 0.8969126 (31.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.23341\n",
      "INFO:tensorflow:loss = 0.21962094, step = 3500 (30.925 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.02927449, train_like_loss = 0.09315535, train_read_comment_loss = 0.09719111 (30.924 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.77230644, train_like_auc = 0.78237534, train_read_comment_auc = 0.89818484 (30.925 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.31559\n",
      "INFO:tensorflow:loss = 0.22433457, step = 3600 (30.161 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.029765613, train_like_loss = 0.08523768, train_read_comment_loss = 0.109331265 (30.162 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.7731192, train_like_auc = 0.7858478, train_read_comment_auc = 0.89853966 (30.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.15371\n",
      "INFO:tensorflow:loss = 0.24202038, step = 3700 (31.710 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.046311986, train_like_loss = 0.10166858, train_read_comment_loss = 0.09403981 (31.710 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.7751225, train_like_auc = 0.7843965, train_read_comment_auc = 0.8995704 (31.710 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.17755\n",
      "INFO:tensorflow:loss = 0.2284461, step = 3800 (31.473 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.0356953, train_like_loss = 0.10344706, train_read_comment_loss = 0.08930373 (31.473 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.7796784, train_like_auc = 0.7856771, train_read_comment_auc = 0.90061307 (31.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.22396\n",
      "INFO:tensorflow:loss = 0.18747924, step = 3900 (31.015 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.035728347, train_like_loss = 0.0764321, train_read_comment_loss = 0.0753188 (31.015 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.78365856, train_like_auc = 0.7882065, train_read_comment_auc = 0.9023338 (31.015 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 4000...\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into model\\model_dir\\PLE\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 4000...\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 3.07899\n",
      "INFO:tensorflow:loss = 0.18222883, step = 4000 (32.479 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.028580263, train_like_loss = 0.06399708, train_read_comment_loss = 0.08965149 (32.478 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.78612673, train_like_auc = 0.789254, train_read_comment_auc = 0.90331984 (32.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.17721\n",
      "INFO:tensorflow:loss = 0.19772413, step = 4100 (31.473 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.03581004, train_like_loss = 0.091937, train_read_comment_loss = 0.06997711 (31.474 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.78702855, train_like_auc = 0.7943159, train_read_comment_auc = 0.9048277 (31.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.25631\n",
      "INFO:tensorflow:loss = 0.20464657, step = 4200 (30.713 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.039063152, train_like_loss = 0.07335904, train_read_comment_loss = 0.092224374 (30.713 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.7919296, train_like_auc = 0.79696983, train_read_comment_auc = 0.90622675 (30.713 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.10506\n",
      "INFO:tensorflow:loss = 0.22101083, step = 4300 (32.202 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.026104566, train_like_loss = 0.07909439, train_read_comment_loss = 0.115811884 (32.202 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.7928556, train_like_auc = 0.80155843, train_read_comment_auc = 0.9069168 (32.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.21409\n",
      "INFO:tensorflow:loss = 0.1987507, step = 4400 (31.114 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.04974941, train_like_loss = 0.09434557, train_read_comment_loss = 0.054655727 (31.114 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.7954459, train_like_auc = 0.8026976, train_read_comment_auc = 0.9075734 (31.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.24669\n",
      "INFO:tensorflow:loss = 0.19963264, step = 4500 (30.801 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.028110491, train_like_loss = 0.059743922, train_read_comment_loss = 0.11177823 (30.801 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.79696614, train_like_auc = 0.8029465, train_read_comment_auc = 0.909683 (30.801 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.2977\n",
      "INFO:tensorflow:loss = 0.20229906, step = 4600 (30.324 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.018343726, train_like_loss = 0.09611408, train_read_comment_loss = 0.087841265 (30.323 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.7975509, train_like_auc = 0.8038439, train_read_comment_auc = 0.91023576 (30.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.24931\n",
      "INFO:tensorflow:loss = 0.15452567, step = 4700 (30.775 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.027737485, train_like_loss = 0.082616225, train_read_comment_loss = 0.044171963 (30.776 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.7982254, train_like_auc = 0.806922, train_read_comment_auc = 0.91141003 (30.776 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.28099\n",
      "INFO:tensorflow:loss = 0.25962743, step = 4800 (30.480 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.02422712, train_like_loss = 0.09717223, train_read_comment_loss = 0.13822809 (30.480 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.79907113, train_like_auc = 0.8093551, train_read_comment_auc = 0.9121941 (30.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.24244\n",
      "INFO:tensorflow:loss = 0.23310076, step = 4900 (30.840 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.02592612, train_like_loss = 0.0933768, train_read_comment_loss = 0.113797836 (30.840 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.8011259, train_like_auc = 0.8115202, train_read_comment_auc = 0.9127946 (30.841 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into model\\model_dir\\PLE\\model.ckpt.\n",
      "WARNING:tensorflow:From C:\\Users\\46581\\miniconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1052: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Tensor(\"dense_input/input_layer/concat:0\", shape=(None, 16), dtype=float32)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-04-02T16:19:00\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model\\model_dir\\PLE\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 46.29241s\n",
      "INFO:tensorflow:Finished evaluation at 2023-04-02-16:19:47\n",
      "INFO:tensorflow:Saving dict for global step 5000: eval_click_avatar_accuracy = 0.9923781, eval_click_avatar_auc = 0.7712782, eval_like_accuracy = 0.97352535, eval_like_auc = 0.7854846, eval_read_comment_accuracy = 0.9669215, eval_read_comment_auc = 0.90731907, global_step = 5000, loss = 0.24259779\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: model\\model_dir\\PLE\\model.ckpt-5000\n",
      "INFO:tensorflow:global_step/sec: 1.24281\n",
      "INFO:tensorflow:loss = 0.1842927, step = 5000 (80.463 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.035441518, train_like_loss = 0.09352508, train_read_comment_loss = 0.055326108 (80.462 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.80079675, train_like_auc = 0.81303436, train_read_comment_auc = 0.91366065 (80.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00971\n",
      "INFO:tensorflow:loss = 0.22382127, step = 5100 (33.226 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.037413914, train_like_loss = 0.08323544, train_read_comment_loss = 0.103171915 (33.226 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.8023397, train_like_auc = 0.8127201, train_read_comment_auc = 0.91441673 (33.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.12845\n",
      "INFO:tensorflow:loss = 0.15495783, step = 5200 (31.965 sec)\n",
      "INFO:tensorflow:train_click_avatar_loss = 0.027725752, train_like_loss = 0.066606, train_read_comment_loss = 0.060626067 (31.965 sec)\n",
      "INFO:tensorflow:train_click_avatar_auc = 0.80464387, train_like_auc = 0.8138382, train_read_comment_auc = 0.9143763 (31.965 sec)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6220/1324277829.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m )\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_and_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\training.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(estimator, train_spec, eval_spec)\u001b[0m\n\u001b[0;32m    502\u001b[0m         '(with task id 0).  Given task id {}'.format(config.task_id))\n\u001b[0;32m    503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    505\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\training.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    643\u001b[0m       tf.compat.v1.logging.info(\n\u001b[0;32m    644\u001b[0m           'Running training and evaluation locally (non-distributed).')\n\u001b[1;32m--> 645\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_local\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m     \u001b[1;31m# Distributed case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\training.py\u001b[0m in \u001b[0;36mrun_local\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    740\u001b[0m     \u001b[0msaving_listeners\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving_listeners\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlistener_for_eval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 742\u001b[1;33m     self._estimator.train(\n\u001b[0m\u001b[0;32m    743\u001b[0m         \u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    744\u001b[0m         \u001b[0mmax_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    361\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss for final step: %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1184\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1186\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1215\u001b[0m                                            self.config)\n\u001b[0;32m   1216\u001b[0m       \u001b[0mglobal_step_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[0m\u001b[0;32m   1218\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m                                              saving_listeners)\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[1;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[0;32m   1531\u001b[0m         \u001b[1;31m# trace should be enabled for every step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1532\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurrent_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1533\u001b[1;33m           \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1534\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mcurrent_step\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1535\u001b[0m         tf.compat.v1.logging.warn('Training with estimator made no steps. '\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    780\u001b[0m       \u001b[0mSame\u001b[0m \u001b[1;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m     \"\"\"\n\u001b[1;32m--> 782\u001b[1;33m     return self._sess.run(\n\u001b[0m\u001b[0;32m    783\u001b[0m         \u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1309\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1310\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1311\u001b[1;33m         return self._sess.run(\n\u001b[0m\u001b[0;32m   1312\u001b[0m             \u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1313\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1399\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1400\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1401\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1402\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1403\u001b[0m       \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     \u001b[1;31m# Do session run.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1468\u001b[0m     \u001b[0mrun_metadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_metadata\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mconfig_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRunMetadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1469\u001b[1;33m     outputs = _WrappedSession.run(\n\u001b[0m\u001b[0;32m   1470\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1471\u001b[0m         \u001b[0mfetches\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mactual_fetches\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1231\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1232\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 967\u001b[1;33m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[0;32m    968\u001b[0m                          run_metadata_ptr)\n\u001b[0;32m    969\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1188\u001b[0m     \u001b[1;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1189\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1190\u001b[1;33m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[0;32m   1191\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[0;32m   1192\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1370\u001b[1;33m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[0;32m   1371\u001b[0m                            run_metadata)\n\u001b[0;32m   1372\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1375\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1376\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1377\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1378\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1379\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1358\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1359\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1360\u001b[1;33m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[0;32m   1361\u001b[0m                                       target_list, run_metadata)\n\u001b[0;32m   1362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1451\u001b[0m   def _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list,\n\u001b[0;32m   1452\u001b[0m                           run_metadata):\n\u001b[1;32m-> 1453\u001b[1;33m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[0;32m   1454\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1455\u001b[0m                                             run_metadata)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "estimator = tf.estimator.Estimator(\n",
    "    model_fn=ple_model_fn,\n",
    "    params=params,\n",
    "    config=tf.estimator.RunConfig(model_dir=model_dir, save_checkpoints_steps=save_checkpoints_steps)\n",
    ")\n",
    "\n",
    "train_spec = tf.estimator.TrainSpec(\n",
    "    input_fn=lambda: train_input_fn(filepath=train_data, example_parser=example_parser,\n",
    "                                    batch_size=batch_size, num_epochs=num_epochs,\n",
    "                                    shuffle_buffer_size=shuffle_buffer_size),\n",
    "    max_steps=train_steps\n",
    ")\n",
    "\n",
    "feature_spec = tf.feature_column.make_parse_example_spec(total_feature_columns)\n",
    "serving_input_receiver_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)\n",
    "exporters = [\n",
    "    tf.estimator.BestExporter(\n",
    "        name=\"best_exporter\",\n",
    "        serving_input_receiver_fn=serving_input_receiver_fn,\n",
    "        exports_to_keep=5)\n",
    "]\n",
    "\n",
    "eval_spec = tf.estimator.EvalSpec(\n",
    "    input_fn=lambda: eval_input_fn(filepath=eval_data, example_parser=example_parser,\n",
    "                                   batch_size=batch_size),\n",
    "    throttle_secs=600,\n",
    "    steps=None,\n",
    "    exporters=exporters\n",
    ")\n",
    "\n",
    "tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe7df982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "Tensor(\"dense_input/input_layer/concat:0\", shape=(None, 16), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\46581\\AppData\\Local\\Temp/ipykernel_6220/2769817402.py:26: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  shared_specific_experts = [tf.compat.v1.layers.dense(input,\n",
      "C:\\Users\\46581\\AppData\\Local\\Temp/ipykernel_6220/2769817402.py:38: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  task_specific_experts = [tf.compat.v1.layers.dense(input,\n",
      "C:\\Users\\46581\\AppData\\Local\\Temp/ipykernel_6220/2769817402.py:54: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  gate = tf.compat.v1.layers.dense(input,\n",
      "C:\\Users\\46581\\AppData\\Local\\Temp/ipykernel_6220/2769817402.py:71: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  all_gate = tf.compat.v1.layers.dense(input,\n",
      "C:\\Users\\46581\\AppData\\Local\\Temp/ipykernel_6220/2289478039.py:44: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  shared_specific_experts_final = [tf.compat.v1.layers.dense(input,\n",
      "C:\\Users\\46581\\AppData\\Local\\Temp/ipykernel_6220/2289478039.py:59: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  task_specific_experts_final = [tf.compat.v1.layers.dense(input,\n",
      "C:\\Users\\46581\\AppData\\Local\\Temp/ipykernel_6220/2289478039.py:73: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  gate = tf.compat.v1.layers.dense(input,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-04-02T19:57:43\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model\\model_dir\\PLE\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 36.05905s\n",
      "INFO:tensorflow:Finished evaluation at 2023-04-02-19:58:19\n",
      "INFO:tensorflow:Saving dict for global step 5000: eval_click_avatar_accuracy = 0.9923781, eval_click_avatar_auc = 0.7712782, eval_like_accuracy = 0.97352535, eval_like_auc = 0.7854846, eval_read_comment_accuracy = 0.9669215, eval_read_comment_auc = 0.90731907, global_step = 5000, loss = 0.24259779\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: model\\model_dir\\PLE\\model.ckpt-5000\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Metrics.\n",
    "metrics = estimator.evaluate(input_fn=lambda: eval_input_fn(filepath=eval_data, example_parser=example_parser,\n",
    "                                                            batch_size=batch_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70390e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_click_avatar_accuracy: 0.9923781\n",
      "eval_click_avatar_auc: 0.7712782\n",
      "eval_like_accuracy: 0.97352535\n",
      "eval_like_auc: 0.7854846\n",
      "eval_read_comment_accuracy: 0.9669215\n",
      "eval_read_comment_auc: 0.90731907\n",
      "global_step: 5000\n",
      "loss: 0.24259779\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Tensor(\"dense_input/input_layer/concat:0\", shape=(None, 16), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\46581\\AppData\\Local\\Temp/ipykernel_6220/2769817402.py:26: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  shared_specific_experts = [tf.compat.v1.layers.dense(input,\n",
      "C:\\Users\\46581\\AppData\\Local\\Temp/ipykernel_6220/2769817402.py:38: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  task_specific_experts = [tf.compat.v1.layers.dense(input,\n",
      "C:\\Users\\46581\\AppData\\Local\\Temp/ipykernel_6220/2769817402.py:54: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  gate = tf.compat.v1.layers.dense(input,\n",
      "C:\\Users\\46581\\AppData\\Local\\Temp/ipykernel_6220/2769817402.py:71: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  all_gate = tf.compat.v1.layers.dense(input,\n",
      "C:\\Users\\46581\\AppData\\Local\\Temp/ipykernel_6220/2289478039.py:44: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  shared_specific_experts_final = [tf.compat.v1.layers.dense(input,\n",
      "C:\\Users\\46581\\AppData\\Local\\Temp/ipykernel_6220/2289478039.py:59: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  task_specific_experts_final = [tf.compat.v1.layers.dense(input,\n",
      "C:\\Users\\46581\\AppData\\Local\\Temp/ipykernel_6220/2289478039.py:73: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  gate = tf.compat.v1.layers.dense(input,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model\\model_dir\\PLE\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "<generator object Estimator.predict at 0x000001F34A352740>\n"
     ]
    }
   ],
   "source": [
    "for key in sorted(metrics):\n",
    "    print('%s: %s' % (key, metrics[key]))\n",
    "\n",
    "results = estimator.predict(input_fn=lambda: eval_input_fn(filepath=eval_data, example_parser=example_parser,\n",
    "                                                           batch_size=batch_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab8103a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'read_comment_probabilities'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'read_comment_probabilities'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6220/1602658045.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicts_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtask_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"task_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mpredicts_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mf\"{task_name}_probabilities\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredicts_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mf\"{task_name}_probabilities\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m# test_df = pd.read_csv(\"../../dataset/wechat_algo_data1/dataframe/test.csv\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# for task_name in params[\"task_names\"]:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3024\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3025\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'read_comment_probabilities'"
     ]
    }
   ],
   "source": [
    "\n",
    "predicts_df = pd.DataFrame.from_dict(results)\n",
    "print(type(predicts_df))\n",
    "for task_name in params[\"task_names\"]:\n",
    "    predicts_df[f\"{task_name}_probabilities\"] = predicts_df[f\"{task_name}_probabilities\"].apply(lambda x: x[0])\n",
    "# test_df = pd.read_csv(\"../../dataset/wechat_algo_data1/dataframe/test.csv\")\n",
    "# for task_name in params[\"task_names\"]:\n",
    "#     predicts_df[task_name] = test_df[task_name]\n",
    "# predicts_df.to_csv(\"predictions.csv\")\n",
    "# print(\"after evaluate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304f7c40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
